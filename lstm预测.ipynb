{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdc6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c8d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler =MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce0487d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>成交额</th>\n",
       "      <th>振幅</th>\n",
       "      <th>涨跌幅</th>\n",
       "      <th>涨跌额</th>\n",
       "      <th>换手率</th>\n",
       "      <th>...</th>\n",
       "      <th>DIF</th>\n",
       "      <th>DEA</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI6</th>\n",
       "      <th>RSI12</th>\n",
       "      <th>CCI 14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>BOLLMID</th>\n",
       "      <th>BOLLUPPER</th>\n",
       "      <th>BOLLLOWER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.72</td>\n",
       "      <td>19.62</td>\n",
       "      <td>19.72</td>\n",
       "      <td>19.36</td>\n",
       "      <td>120763</td>\n",
       "      <td>269586496</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167664</td>\n",
       "      <td>-0.249047</td>\n",
       "      <td>0.162765</td>\n",
       "      <td>54.181109</td>\n",
       "      <td>49.427043</td>\n",
       "      <td>57.415079</td>\n",
       "      <td>-226454</td>\n",
       "      <td>19.5270</td>\n",
       "      <td>20.593664</td>\n",
       "      <td>18.460336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.49</td>\n",
       "      <td>20.02</td>\n",
       "      <td>20.13</td>\n",
       "      <td>19.42</td>\n",
       "      <td>174185</td>\n",
       "      <td>395652016</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115555</td>\n",
       "      <td>-0.222348</td>\n",
       "      <td>0.213587</td>\n",
       "      <td>65.356418</td>\n",
       "      <td>54.866154</td>\n",
       "      <td>105.018272</td>\n",
       "      <td>-52269</td>\n",
       "      <td>19.4865</td>\n",
       "      <td>20.394575</td>\n",
       "      <td>18.578425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.02</td>\n",
       "      <td>20.42</td>\n",
       "      <td>20.56</td>\n",
       "      <td>19.74</td>\n",
       "      <td>170104</td>\n",
       "      <td>390894016</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.24</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041502</td>\n",
       "      <td>-0.186179</td>\n",
       "      <td>0.289354</td>\n",
       "      <td>73.200231</td>\n",
       "      <td>59.605520</td>\n",
       "      <td>146.317531</td>\n",
       "      <td>117835</td>\n",
       "      <td>19.4860</td>\n",
       "      <td>20.391896</td>\n",
       "      <td>18.580104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.16</td>\n",
       "      <td>20.16</td>\n",
       "      <td>20.89</td>\n",
       "      <td>19.92</td>\n",
       "      <td>171740</td>\n",
       "      <td>398464240</td>\n",
       "      <td>4.75</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003752</td>\n",
       "      <td>-0.149694</td>\n",
       "      <td>0.291884</td>\n",
       "      <td>62.213173</td>\n",
       "      <td>55.474890</td>\n",
       "      <td>139.382920</td>\n",
       "      <td>-53905</td>\n",
       "      <td>19.4920</td>\n",
       "      <td>20.414778</td>\n",
       "      <td>18.569222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.16</td>\n",
       "      <td>19.68</td>\n",
       "      <td>20.16</td>\n",
       "      <td>19.46</td>\n",
       "      <td>109746</td>\n",
       "      <td>247257153</td>\n",
       "      <td>3.47</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012423</td>\n",
       "      <td>-0.122239</td>\n",
       "      <td>0.219633</td>\n",
       "      <td>46.688351</td>\n",
       "      <td>48.680627</td>\n",
       "      <td>44.100930</td>\n",
       "      <td>-163651</td>\n",
       "      <td>19.4890</td>\n",
       "      <td>20.408769</td>\n",
       "      <td>18.569231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>54.58</td>\n",
       "      <td>54.90</td>\n",
       "      <td>54.94</td>\n",
       "      <td>53.90</td>\n",
       "      <td>72188</td>\n",
       "      <td>392398397</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715365</td>\n",
       "      <td>0.393055</td>\n",
       "      <td>0.644619</td>\n",
       "      <td>79.186993</td>\n",
       "      <td>69.045539</td>\n",
       "      <td>123.824630</td>\n",
       "      <td>25848582</td>\n",
       "      <td>52.4245</td>\n",
       "      <td>54.932126</td>\n",
       "      <td>49.916874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>54.65</td>\n",
       "      <td>53.80</td>\n",
       "      <td>55.10</td>\n",
       "      <td>53.43</td>\n",
       "      <td>72414</td>\n",
       "      <td>392881235</td>\n",
       "      <td>3.04</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697935</td>\n",
       "      <td>0.454031</td>\n",
       "      <td>0.487807</td>\n",
       "      <td>54.951124</td>\n",
       "      <td>57.841573</td>\n",
       "      <td>80.582940</td>\n",
       "      <td>25776168</td>\n",
       "      <td>52.5535</td>\n",
       "      <td>55.065671</td>\n",
       "      <td>50.041329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>53.65</td>\n",
       "      <td>53.46</td>\n",
       "      <td>53.93</td>\n",
       "      <td>52.85</td>\n",
       "      <td>64723</td>\n",
       "      <td>346058717</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649202</td>\n",
       "      <td>0.493066</td>\n",
       "      <td>0.312274</td>\n",
       "      <td>49.349025</td>\n",
       "      <td>54.840921</td>\n",
       "      <td>32.139078</td>\n",
       "      <td>25711445</td>\n",
       "      <td>52.6785</td>\n",
       "      <td>55.104120</td>\n",
       "      <td>50.252880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>53.25</td>\n",
       "      <td>53.21</td>\n",
       "      <td>53.60</td>\n",
       "      <td>53.00</td>\n",
       "      <td>42471</td>\n",
       "      <td>226247678</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583681</td>\n",
       "      <td>0.511189</td>\n",
       "      <td>0.144984</td>\n",
       "      <td>45.276279</td>\n",
       "      <td>52.650015</td>\n",
       "      <td>15.125516</td>\n",
       "      <td>25668974</td>\n",
       "      <td>52.7565</td>\n",
       "      <td>55.142876</td>\n",
       "      <td>50.370124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>53.00</td>\n",
       "      <td>51.36</td>\n",
       "      <td>53.00</td>\n",
       "      <td>51.28</td>\n",
       "      <td>90643</td>\n",
       "      <td>472475304</td>\n",
       "      <td>3.23</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378116</td>\n",
       "      <td>0.484574</td>\n",
       "      <td>-0.212916</td>\n",
       "      <td>26.128048</td>\n",
       "      <td>39.810762</td>\n",
       "      <td>-94.923951</td>\n",
       "      <td>25578331</td>\n",
       "      <td>52.6995</td>\n",
       "      <td>55.164826</td>\n",
       "      <td>50.234174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2161 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open  Close   High    Low  Volume        成交额    振幅   涨跌幅   涨跌额   换手率  \\\n",
       "0     19.72  19.62  19.72  19.36  120763  269586496  1.83 -0.41 -0.08  0.92   \n",
       "1     19.49  20.02  20.13  19.42  174185  395652016  3.62  2.04  0.40  1.27   \n",
       "2     20.02  20.42  20.56  19.74  170104  390894016  4.10  2.00  0.40  1.24   \n",
       "3     20.16  20.16  20.89  19.92  171740  398464240  4.75 -1.27 -0.26  1.25   \n",
       "4     20.16  19.68  20.16  19.46  109746  247257153  3.47 -2.38 -0.48  0.80   \n",
       "...     ...    ...    ...    ...     ...        ...   ...   ...   ...   ...   \n",
       "2156  54.58  54.90  54.94  53.90   72188  392398397  1.90  0.46  0.25  0.53   \n",
       "2157  54.65  53.80  55.10  53.43   72414  392881235  3.04 -2.00 -1.10  0.53   \n",
       "2158  53.65  53.46  53.93  52.85   64723  346058717  2.01 -0.63 -0.34  0.47   \n",
       "2159  53.25  53.21  53.60  53.00   42471  226247678  1.12 -0.47 -0.25  0.31   \n",
       "2160  53.00  51.36  53.00  51.28   90643  472475304  3.23 -3.48 -1.85  0.66   \n",
       "\n",
       "      ...       DIF       DEA      MACD       RSI6      RSI12      CCI 14  \\\n",
       "0     ... -0.167664 -0.249047  0.162765  54.181109  49.427043   57.415079   \n",
       "1     ... -0.115555 -0.222348  0.213587  65.356418  54.866154  105.018272   \n",
       "2     ... -0.041502 -0.186179  0.289354  73.200231  59.605520  146.317531   \n",
       "3     ... -0.003752 -0.149694  0.291884  62.213173  55.474890  139.382920   \n",
       "4     ... -0.012423 -0.122239  0.219633  46.688351  48.680627   44.100930   \n",
       "...   ...       ...       ...       ...        ...        ...         ...   \n",
       "2156  ...  0.715365  0.393055  0.644619  79.186993  69.045539  123.824630   \n",
       "2157  ...  0.697935  0.454031  0.487807  54.951124  57.841573   80.582940   \n",
       "2158  ...  0.649202  0.493066  0.312274  49.349025  54.840921   32.139078   \n",
       "2159  ...  0.583681  0.511189  0.144984  45.276279  52.650015   15.125516   \n",
       "2160  ...  0.378116  0.484574 -0.212916  26.128048  39.810762  -94.923951   \n",
       "\n",
       "           OBV  BOLLMID  BOLLUPPER  BOLLLOWER  \n",
       "0      -226454  19.5270  20.593664  18.460336  \n",
       "1       -52269  19.4865  20.394575  18.578425  \n",
       "2       117835  19.4860  20.391896  18.580104  \n",
       "3       -53905  19.4920  20.414778  18.569222  \n",
       "4      -163651  19.4890  20.408769  18.569231  \n",
       "...        ...      ...        ...        ...  \n",
       "2156  25848582  52.4245  54.932126  49.916874  \n",
       "2157  25776168  52.5535  55.065671  50.041329  \n",
       "2158  25711445  52.6785  55.104120  50.252880  \n",
       "2159  25668974  52.7565  55.142876  50.370124  \n",
       "2160  25578331  52.6995  55.164826  50.234174  \n",
       "\n",
       "[2161 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_excel('600085done.xlsx')\n",
    "data=data.drop(columns=['Date'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625da2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['Close'],axis=1)\n",
    "Y=data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663bda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split#用于划分训练集和测试集\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.7,shuffle=False)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c843099",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:16:36.437846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:36.439600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:36.441507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:16:36.690390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:36.692076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:36.693736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-12 17:16:37.032628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:37.034728: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:37.036740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-12 17:16:37.284167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:37.288242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:37.293531: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-12 17:16:38.519688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:38.522481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:38.524112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-12 17:16:38.817008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:38.819062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:38.820981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/16 [===========================>..] - ETA: 0s - loss: 708.2778 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:16:42.615843: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:42.618792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:42.620533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-12 17:16:42.876135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:16:42.877932: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:16:42.879651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 7s 162ms/step - loss: 706.1780 - acc: 0.0000e+00 - val_loss: 1353.5599 - val_acc: 0.0000e+00\n",
      "Epoch 2/32\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 158.8242 - acc: 0.0000e+00 - val_loss: 566.2585 - val_acc: 0.0000e+00\n",
      "Epoch 3/32\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 16.8948 - acc: 0.0000e+00 - val_loss: 318.7618 - val_acc: 0.0000e+00\n",
      "Epoch 4/32\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 14.7339 - acc: 0.0000e+00 - val_loss: 343.7232 - val_acc: 0.0000e+00\n",
      "Epoch 5/32\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 11.9590 - acc: 0.0000e+00 - val_loss: 388.8138 - val_acc: 0.0000e+00\n",
      "Epoch 6/32\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 11.9244 - acc: 0.0000e+00 - val_loss: 382.1716 - val_acc: 0.0000e+00\n",
      "Epoch 7/32\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 11.8049 - acc: 0.0000e+00 - val_loss: 371.3720 - val_acc: 0.0000e+00\n",
      "Epoch 8/32\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 11.8056 - acc: 0.0000e+00 - val_loss: 380.2051 - val_acc: 0.0000e+00\n",
      "Epoch 9/32\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 11.7854 - acc: 0.0000e+00 - val_loss: 374.6319 - val_acc: 0.0000e+00\n",
      "Epoch 10/32\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 11.7915 - acc: 0.0000e+00 - val_loss: 378.8963 - val_acc: 0.0000e+00\n",
      "Epoch 11/32\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 11.7836 - acc: 0.0000e+00 - val_loss: 370.7669 - val_acc: 0.0000e+00\n",
      "Epoch 12/32\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 11.8100 - acc: 0.0000e+00 - val_loss: 372.9221 - val_acc: 0.0000e+00\n",
      "Epoch 13/32\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 11.7971 - acc: 0.0000e+00 - val_loss: 379.9120 - val_acc: 0.0000e+00\n",
      "Epoch 14/32\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 11.7857 - acc: 0.0000e+00 - val_loss: 375.0214 - val_acc: 0.0000e+00\n",
      "Epoch 15/32\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 11.7787 - acc: 0.0000e+00 - val_loss: 375.1989 - val_acc: 0.0000e+00\n",
      "Epoch 16/32\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 11.7978 - acc: 0.0000e+00 - val_loss: 376.8801 - val_acc: 0.0000e+00\n",
      "Epoch 17/32\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 11.7849 - acc: 0.0000e+00 - val_loss: 376.2536 - val_acc: 0.0000e+00\n",
      "Epoch 18/32\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 11.7885 - acc: 0.0000e+00 - val_loss: 375.0101 - val_acc: 0.0000e+00\n",
      "Epoch 19/32\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 11.7777 - acc: 0.0000e+00 - val_loss: 375.5013 - val_acc: 0.0000e+00\n",
      "Epoch 20/32\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 11.7823 - acc: 0.0000e+00 - val_loss: 372.4555 - val_acc: 0.0000e+00\n",
      "Epoch 21/32\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 11.7806 - acc: 0.0000e+00 - val_loss: 374.5262 - val_acc: 0.0000e+00\n",
      "Epoch 22/32\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 11.7753 - acc: 0.0000e+00 - val_loss: 378.2915 - val_acc: 0.0000e+00\n",
      "Epoch 23/32\n",
      "16/16 [==============================] - 1s 95ms/step - loss: 11.7675 - acc: 0.0000e+00 - val_loss: 373.4794 - val_acc: 0.0000e+00\n",
      "Epoch 24/32\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 11.7799 - acc: 0.0000e+00 - val_loss: 374.2352 - val_acc: 0.0000e+00\n",
      "Epoch 25/32\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 11.7819 - acc: 0.0000e+00 - val_loss: 375.9749 - val_acc: 0.0000e+00\n",
      "Epoch 26/32\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 11.8074 - acc: 0.0000e+00 - val_loss: 375.5234 - val_acc: 0.0000e+00\n",
      "Epoch 27/32\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 11.7533 - acc: 0.0000e+00 - val_loss: 373.7956 - val_acc: 0.0000e+00\n",
      "Epoch 28/32\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 11.7036 - acc: 0.0000e+00 - val_loss: 375.8066 - val_acc: 0.0000e+00\n",
      "Epoch 29/32\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 11.4796 - acc: 0.0000e+00 - val_loss: 373.2911 - val_acc: 0.0000e+00\n",
      "Epoch 30/32\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 10.8802 - acc: 0.0000e+00 - val_loss: 367.7329 - val_acc: 0.0000e+00\n",
      "Epoch 31/32\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 9.7277 - acc: 0.0000e+00 - val_loss: 373.7154 - val_acc: 0.0000e+00\n",
      "Epoch 32/32\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 8.9790 - acc: 0.0000e+00 - val_loss: 335.3254 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "# 构建LSTM模型\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128,return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['acc'])\n",
    "# 训练榄型\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100,epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d48ea3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 17:17:30.468268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:17:30.470199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:17:30.472109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-12 17:17:30.751029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-12 17:17:30.752798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-12 17:17:30.754591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.758593],\n",
       "       [27.446554],\n",
       "       [30.2229  ],\n",
       "       [27.461031],\n",
       "       [27.453602],\n",
       "       [27.44818 ],\n",
       "       [27.445244],\n",
       "       [29.765242],\n",
       "       [30.223417],\n",
       "       [30.223507],\n",
       "       [30.223816],\n",
       "       [29.752333],\n",
       "       [29.234098],\n",
       "       [28.971233],\n",
       "       [27.461916],\n",
       "       [27.46322 ],\n",
       "       [27.4611  ],\n",
       "       [27.467022],\n",
       "       [27.457836],\n",
       "       [27.465382],\n",
       "       [27.483503],\n",
       "       [27.457449],\n",
       "       [27.456255],\n",
       "       [27.453478],\n",
       "       [27.455307],\n",
       "       [27.458889],\n",
       "       [27.458197],\n",
       "       [27.46119 ],\n",
       "       [27.455282],\n",
       "       [27.460293],\n",
       "       [30.206665],\n",
       "       [30.227774],\n",
       "       [30.227844],\n",
       "       [30.227842],\n",
       "       [29.775131],\n",
       "       [27.468786],\n",
       "       [29.162512],\n",
       "       [27.45678 ],\n",
       "       [27.45903 ],\n",
       "       [27.454731],\n",
       "       [27.453978],\n",
       "       [27.45521 ],\n",
       "       [27.45876 ],\n",
       "       [27.456625],\n",
       "       [27.463367],\n",
       "       [30.2264  ],\n",
       "       [27.472599],\n",
       "       [27.552685],\n",
       "       [27.472485],\n",
       "       [27.465452],\n",
       "       [27.465807],\n",
       "       [27.45982 ],\n",
       "       [27.456625],\n",
       "       [27.455551],\n",
       "       [27.453524],\n",
       "       [27.45675 ],\n",
       "       [27.455074],\n",
       "       [27.454203],\n",
       "       [27.453537],\n",
       "       [27.452085],\n",
       "       [27.456802],\n",
       "       [27.455042],\n",
       "       [27.451996],\n",
       "       [27.450298],\n",
       "       [27.449806],\n",
       "       [27.452705],\n",
       "       [27.448273],\n",
       "       [27.448553],\n",
       "       [27.44489 ],\n",
       "       [27.443872],\n",
       "       [27.443705],\n",
       "       [27.44463 ],\n",
       "       [27.455904],\n",
       "       [27.44917 ],\n",
       "       [27.447565],\n",
       "       [27.44843 ],\n",
       "       [27.445877],\n",
       "       [27.44646 ],\n",
       "       [27.443148],\n",
       "       [27.452698],\n",
       "       [27.458544],\n",
       "       [27.455181],\n",
       "       [27.452389],\n",
       "       [27.454393],\n",
       "       [27.451601],\n",
       "       [27.449215],\n",
       "       [27.446304],\n",
       "       [27.444975],\n",
       "       [27.442127],\n",
       "       [27.441355],\n",
       "       [27.439487],\n",
       "       [27.43947 ],\n",
       "       [27.438675],\n",
       "       [27.44332 ],\n",
       "       [27.438091],\n",
       "       [27.435677],\n",
       "       [27.436039],\n",
       "       [27.4404  ],\n",
       "       [27.440577],\n",
       "       [27.438822],\n",
       "       [27.453913],\n",
       "       [27.449814],\n",
       "       [27.448475],\n",
       "       [27.44612 ],\n",
       "       [27.449802],\n",
       "       [27.444979],\n",
       "       [27.442617],\n",
       "       [27.44233 ],\n",
       "       [27.44086 ],\n",
       "       [27.441542],\n",
       "       [27.437649],\n",
       "       [27.43589 ],\n",
       "       [27.439491],\n",
       "       [27.452194],\n",
       "       [27.44785 ],\n",
       "       [27.450548],\n",
       "       [27.450148],\n",
       "       [27.447762],\n",
       "       [27.44458 ],\n",
       "       [27.445032],\n",
       "       [27.444576],\n",
       "       [27.442297],\n",
       "       [27.44181 ],\n",
       "       [27.44245 ],\n",
       "       [27.451212],\n",
       "       [27.448458],\n",
       "       [27.44425 ],\n",
       "       [27.448174],\n",
       "       [27.4458  ],\n",
       "       [27.467024],\n",
       "       [27.452978],\n",
       "       [29.763504],\n",
       "       [27.459625],\n",
       "       [27.457193],\n",
       "       [27.456253],\n",
       "       [27.466402],\n",
       "       [27.465534],\n",
       "       [27.457022],\n",
       "       [27.459618],\n",
       "       [27.47491 ],\n",
       "       [27.467236],\n",
       "       [27.465837],\n",
       "       [27.46391 ],\n",
       "       [27.465908],\n",
       "       [27.46408 ],\n",
       "       [27.462576],\n",
       "       [27.472605],\n",
       "       [27.489166],\n",
       "       [29.066807],\n",
       "       [27.482506],\n",
       "       [30.229298],\n",
       "       [29.79178 ],\n",
       "       [30.229322],\n",
       "       [30.229137],\n",
       "       [29.789913],\n",
       "       [29.787653],\n",
       "       [27.490631],\n",
       "       [30.229946],\n",
       "       [30.229927],\n",
       "       [30.229887],\n",
       "       [30.229788],\n",
       "       [30.229902],\n",
       "       [30.23023 ],\n",
       "       [30.230429],\n",
       "       [30.23097 ],\n",
       "       [30.231487],\n",
       "       [30.231987],\n",
       "       [30.232462],\n",
       "       [30.23286 ],\n",
       "       [29.886618],\n",
       "       [30.23351 ],\n",
       "       [30.233644],\n",
       "       [29.926113],\n",
       "       [27.509174],\n",
       "       [27.513472],\n",
       "       [27.502071],\n",
       "       [27.500057],\n",
       "       [27.502886],\n",
       "       [27.502491],\n",
       "       [30.233633],\n",
       "       [30.233698],\n",
       "       [29.257303],\n",
       "       [27.497026],\n",
       "       [29.094536],\n",
       "       [27.49627 ],\n",
       "       [27.495596],\n",
       "       [27.493992],\n",
       "       [27.501694],\n",
       "       [27.492023],\n",
       "       [27.495508],\n",
       "       [28.99416 ],\n",
       "       [29.784029],\n",
       "       [29.80638 ],\n",
       "       [27.506973],\n",
       "       [30.232822],\n",
       "       [29.80138 ],\n",
       "       [29.78714 ],\n",
       "       [27.50787 ],\n",
       "       [27.54728 ],\n",
       "       [27.490393],\n",
       "       [27.50143 ],\n",
       "       [29.030933],\n",
       "       [27.49181 ],\n",
       "       [27.48257 ],\n",
       "       [27.487024],\n",
       "       [27.489737],\n",
       "       [27.486956],\n",
       "       [27.48721 ],\n",
       "       [27.483112],\n",
       "       [30.231543],\n",
       "       [27.493536],\n",
       "       [27.501686],\n",
       "       [27.497696],\n",
       "       [30.23194 ],\n",
       "       [29.936327],\n",
       "       [30.231972],\n",
       "       [27.511223],\n",
       "       [30.231499],\n",
       "       [27.499313],\n",
       "       [27.498392],\n",
       "       [27.492338],\n",
       "       [27.488987],\n",
       "       [27.483044],\n",
       "       [27.486235],\n",
       "       [27.488544],\n",
       "       [27.484354],\n",
       "       [27.487083],\n",
       "       [27.483643],\n",
       "       [27.480669],\n",
       "       [27.476658],\n",
       "       [27.4699  ],\n",
       "       [27.467356],\n",
       "       [27.47046 ],\n",
       "       [27.463545],\n",
       "       [27.466852],\n",
       "       [27.478268],\n",
       "       [27.491674],\n",
       "       [27.47354 ],\n",
       "       [27.47459 ],\n",
       "       [27.478228],\n",
       "       [27.477285],\n",
       "       [27.482042],\n",
       "       [27.487734],\n",
       "       [27.48286 ],\n",
       "       [27.47733 ],\n",
       "       [27.474161],\n",
       "       [27.486351],\n",
       "       [27.482828],\n",
       "       [27.476421],\n",
       "       [27.48075 ],\n",
       "       [28.978827],\n",
       "       [27.499329],\n",
       "       [27.516079],\n",
       "       [27.531847],\n",
       "       [27.506985],\n",
       "       [27.50769 ],\n",
       "       [27.510977],\n",
       "       [27.525805],\n",
       "       [27.517275],\n",
       "       [27.513067],\n",
       "       [27.524456],\n",
       "       [30.23291 ],\n",
       "       [28.557158],\n",
       "       [30.221764],\n",
       "       [30.23325 ],\n",
       "       [30.233484],\n",
       "       [30.233625],\n",
       "       [30.23396 ],\n",
       "       [30.234264],\n",
       "       [30.234543],\n",
       "       [30.234745],\n",
       "       [30.234976],\n",
       "       [30.235065],\n",
       "       [30.235329],\n",
       "       [30.235617],\n",
       "       [30.235907],\n",
       "       [30.236128],\n",
       "       [30.228369],\n",
       "       [29.921324],\n",
       "       [28.491962],\n",
       "       [29.024231],\n",
       "       [29.08065 ],\n",
       "       [27.548601],\n",
       "       [27.530678],\n",
       "       [29.116564],\n",
       "       [30.23512 ],\n",
       "       [30.230206],\n",
       "       [27.533773],\n",
       "       [29.042204],\n",
       "       [27.532217],\n",
       "       [28.841183],\n",
       "       [27.872261],\n",
       "       [29.810883],\n",
       "       [27.61061 ],\n",
       "       [27.54614 ],\n",
       "       [27.524693],\n",
       "       [27.51484 ],\n",
       "       [27.510517],\n",
       "       [29.832388],\n",
       "       [30.236013],\n",
       "       [27.59603 ],\n",
       "       [29.278688],\n",
       "       [27.561972],\n",
       "       [27.550236],\n",
       "       [27.569578],\n",
       "       [29.045328],\n",
       "       [27.54415 ],\n",
       "       [27.53315 ],\n",
       "       [27.524668],\n",
       "       [27.522434],\n",
       "       [27.51457 ],\n",
       "       [29.0547  ],\n",
       "       [27.581789],\n",
       "       [27.52251 ],\n",
       "       [27.519865],\n",
       "       [27.585375],\n",
       "       [27.534111],\n",
       "       [27.521809],\n",
       "       [29.803867],\n",
       "       [27.509256],\n",
       "       [27.505682],\n",
       "       [27.503101],\n",
       "       [27.508764],\n",
       "       [27.504618],\n",
       "       [27.510696],\n",
       "       [27.509634],\n",
       "       [27.530142],\n",
       "       [27.507349],\n",
       "       [27.510666],\n",
       "       [27.503304],\n",
       "       [27.500265],\n",
       "       [27.51547 ],\n",
       "       [27.501186],\n",
       "       [27.495499],\n",
       "       [27.499199],\n",
       "       [27.497053],\n",
       "       [27.503958],\n",
       "       [27.501171],\n",
       "       [27.507767],\n",
       "       [27.512226],\n",
       "       [27.513302],\n",
       "       [27.525854],\n",
       "       [27.519506],\n",
       "       [27.530378],\n",
       "       [30.233988],\n",
       "       [30.233812],\n",
       "       [30.233576],\n",
       "       [30.2337  ],\n",
       "       [29.953438],\n",
       "       [30.233099],\n",
       "       [30.233774],\n",
       "       [30.233988],\n",
       "       [30.234114],\n",
       "       [30.234077],\n",
       "       [27.514662],\n",
       "       [30.234959],\n",
       "       [30.060104],\n",
       "       [30.23542 ],\n",
       "       [29.020658],\n",
       "       [30.2356  ],\n",
       "       [29.421432],\n",
       "       [29.769258],\n",
       "       [28.913733],\n",
       "       [27.522264],\n",
       "       [27.529963],\n",
       "       [30.235872],\n",
       "       [29.116909],\n",
       "       [27.523054],\n",
       "       [27.61753 ],\n",
       "       [27.54963 ],\n",
       "       [27.518127],\n",
       "       [27.514027],\n",
       "       [27.521196],\n",
       "       [27.518852],\n",
       "       [27.524048],\n",
       "       [27.524254],\n",
       "       [27.546227],\n",
       "       [30.160597],\n",
       "       [30.235292],\n",
       "       [27.532265],\n",
       "       [30.233696],\n",
       "       [29.091742],\n",
       "       [27.55949 ],\n",
       "       [27.539873],\n",
       "       [30.235628],\n",
       "       [30.235628],\n",
       "       [29.807434],\n",
       "       [27.871101],\n",
       "       [27.513771],\n",
       "       [27.519478],\n",
       "       [27.511534],\n",
       "       [27.508125],\n",
       "       [27.507513],\n",
       "       [27.505062],\n",
       "       [27.501219],\n",
       "       [27.509388],\n",
       "       [27.505606],\n",
       "       [27.503366],\n",
       "       [27.503279],\n",
       "       [27.50236 ],\n",
       "       [27.509607],\n",
       "       [27.510088],\n",
       "       [27.515142],\n",
       "       [28.938398],\n",
       "       [27.49579 ],\n",
       "       [28.98919 ],\n",
       "       [29.80155 ],\n",
       "       [27.511883],\n",
       "       [27.516129],\n",
       "       [30.233166],\n",
       "       [27.5177  ],\n",
       "       [27.511877],\n",
       "       [27.521994],\n",
       "       [27.533651],\n",
       "       [30.23395 ],\n",
       "       [27.520353],\n",
       "       [27.51594 ],\n",
       "       [27.51748 ],\n",
       "       [27.51006 ],\n",
       "       [27.50977 ],\n",
       "       [27.504162],\n",
       "       [27.501305],\n",
       "       [27.502766],\n",
       "       [27.504688],\n",
       "       [27.521439],\n",
       "       [27.512648],\n",
       "       [27.549997],\n",
       "       [29.806953],\n",
       "       [30.235197],\n",
       "       [28.305908],\n",
       "       [29.810516],\n",
       "       [27.539211],\n",
       "       [27.533468],\n",
       "       [27.526344],\n",
       "       [27.52925 ],\n",
       "       [29.698458],\n",
       "       [28.213076],\n",
       "       [27.547693],\n",
       "       [27.531998],\n",
       "       [30.235245],\n",
       "       [30.23553 ],\n",
       "       [27.655954],\n",
       "       [27.61529 ],\n",
       "       [27.533234],\n",
       "       [30.23611 ],\n",
       "       [28.992355],\n",
       "       [30.236435],\n",
       "       [30.236391],\n",
       "       [30.236465],\n",
       "       [29.830635],\n",
       "       [27.565891],\n",
       "       [27.553272],\n",
       "       [30.236763],\n",
       "       [30.236504],\n",
       "       [29.818762],\n",
       "       [30.236866],\n",
       "       [30.236712],\n",
       "       [30.23676 ],\n",
       "       [30.236595],\n",
       "       [30.236746],\n",
       "       [30.236511],\n",
       "       [30.23655 ],\n",
       "       [30.236715],\n",
       "       [30.236912],\n",
       "       [30.236984],\n",
       "       [30.237164],\n",
       "       [30.23727 ],\n",
       "       [30.23738 ],\n",
       "       [30.23747 ],\n",
       "       [30.237709],\n",
       "       [30.237951],\n",
       "       [30.238188],\n",
       "       [30.238382],\n",
       "       [30.23866 ],\n",
       "       [30.238693],\n",
       "       [30.23914 ],\n",
       "       [30.239107],\n",
       "       [30.239128],\n",
       "       [30.238632],\n",
       "       [30.238821],\n",
       "       [30.238712],\n",
       "       [30.238829],\n",
       "       [30.239006],\n",
       "       [30.239182],\n",
       "       [30.239294],\n",
       "       [30.23939 ],\n",
       "       [30.239504],\n",
       "       [30.239676],\n",
       "       [30.239807],\n",
       "       [30.239891],\n",
       "       [30.24003 ],\n",
       "       [30.24026 ],\n",
       "       [30.240408],\n",
       "       [30.240494],\n",
       "       [30.240385],\n",
       "       [30.240446],\n",
       "       [30.240551],\n",
       "       [30.24056 ],\n",
       "       [30.240707],\n",
       "       [30.240734],\n",
       "       [30.240776],\n",
       "       [30.240763],\n",
       "       [30.240715],\n",
       "       [30.240692],\n",
       "       [30.240637],\n",
       "       [30.240507],\n",
       "       [30.240416],\n",
       "       [30.240316],\n",
       "       [30.240261],\n",
       "       [30.240154],\n",
       "       [30.240074],\n",
       "       [30.240007],\n",
       "       [30.239838],\n",
       "       [30.239748],\n",
       "       [30.239702],\n",
       "       [30.239717],\n",
       "       [30.239683],\n",
       "       [30.239641],\n",
       "       [30.239794],\n",
       "       [30.239803],\n",
       "       [30.239796],\n",
       "       [30.239677],\n",
       "       [30.239544],\n",
       "       [30.23934 ],\n",
       "       [29.896906],\n",
       "       [30.23089 ],\n",
       "       [30.211811],\n",
       "       [29.11492 ],\n",
       "       [30.238674],\n",
       "       [30.23183 ],\n",
       "       [29.047707],\n",
       "       [28.966871],\n",
       "       [29.091093],\n",
       "       [29.820492],\n",
       "       [30.237055],\n",
       "       [29.768162],\n",
       "       [29.015852],\n",
       "       [30.234854],\n",
       "       [30.237932],\n",
       "       [29.8282  ],\n",
       "       [29.063606],\n",
       "       [30.238264],\n",
       "       [30.237839],\n",
       "       [30.237778],\n",
       "       [30.23755 ],\n",
       "       [30.237608],\n",
       "       [30.237566],\n",
       "       [30.237593],\n",
       "       [30.237524],\n",
       "       [30.237568],\n",
       "       [30.237623],\n",
       "       [30.237684],\n",
       "       [30.237978],\n",
       "       [30.238222],\n",
       "       [30.238333],\n",
       "       [30.238428],\n",
       "       [30.23867 ],\n",
       "       [30.238852],\n",
       "       [30.239079],\n",
       "       [30.239334],\n",
       "       [30.239803],\n",
       "       [30.240156],\n",
       "       [30.24022 ],\n",
       "       [30.240232],\n",
       "       [30.240196],\n",
       "       [30.240112],\n",
       "       [30.240036],\n",
       "       [30.239882],\n",
       "       [30.239931],\n",
       "       [30.239845],\n",
       "       [30.239782],\n",
       "       [30.239801],\n",
       "       [30.239685],\n",
       "       [30.239632],\n",
       "       [30.2395  ],\n",
       "       [30.238762],\n",
       "       [30.233788],\n",
       "       [30.239126],\n",
       "       [30.239359],\n",
       "       [30.239405],\n",
       "       [30.239374],\n",
       "       [30.239353],\n",
       "       [30.239408],\n",
       "       [30.239157],\n",
       "       [30.238798],\n",
       "       [30.235985],\n",
       "       [29.831535],\n",
       "       [30.187733],\n",
       "       [29.81062 ],\n",
       "       [29.027859],\n",
       "       [28.660694],\n",
       "       [29.012335],\n",
       "       [28.782621],\n",
       "       [29.227556],\n",
       "       [28.30441 ],\n",
       "       [27.569368],\n",
       "       [30.23734 ],\n",
       "       [30.237322],\n",
       "       [30.237358],\n",
       "       [30.237371],\n",
       "       [29.816797],\n",
       "       [29.816814],\n",
       "       [30.237429],\n",
       "       [29.765316],\n",
       "       [30.039745],\n",
       "       [27.556425],\n",
       "       [30.184107],\n",
       "       [28.947258],\n",
       "       [27.557602],\n",
       "       [27.69028 ],\n",
       "       [27.537004],\n",
       "       [27.722944],\n",
       "       [30.237534],\n",
       "       [29.999367],\n",
       "       [29.740274],\n",
       "       [29.829958],\n",
       "       [30.237633],\n",
       "       [30.237646],\n",
       "       [30.23764 ],\n",
       "       [30.237587],\n",
       "       [30.237597],\n",
       "       [30.237621],\n",
       "       [30.237577],\n",
       "       [30.237703],\n",
       "       [30.2371  ],\n",
       "       [29.052542],\n",
       "       [29.140205],\n",
       "       [30.237154],\n",
       "       [30.237984],\n",
       "       [30.237137],\n",
       "       [30.074497],\n",
       "       [29.826693],\n",
       "       [29.837147],\n",
       "       [28.975485],\n",
       "       [29.035711],\n",
       "       [30.075903],\n",
       "       [30.220749],\n",
       "       [30.238232],\n",
       "       [30.236008],\n",
       "       [30.238197],\n",
       "       [30.238194],\n",
       "       [30.238132],\n",
       "       [30.237997],\n",
       "       [30.237955],\n",
       "       [30.237974],\n",
       "       [30.238157],\n",
       "       [30.238276],\n",
       "       [30.238138],\n",
       "       [30.237988]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prices = model.predict(X_test)\n",
    "predicted_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc5a186",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predd=[]\n",
    "for i in range(len(predicted_prices)):\n",
    "    predd.append(predicted_prices[i][0])\n",
    "\n",
    "gd=[]\n",
    "for i in range(len(predd)-1):\n",
    "    if predd[i]<predd[i+1]:\n",
    "        gd.append(1)\n",
    "    else:\n",
    "        gd.append(0)\n",
    "gd.append(0)\n",
    "gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ea68149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211093990755008"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_excel('600085copy.xlsx')\n",
    "data=data.drop(columns=['Date','Close'])\n",
    "X=data.drop(['updowm'],axis=1)\n",
    "Y=data['updowm']\n",
    "from sklearn.model_selection import train_test_split#用于划分训练集和测试集\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.7,shuffle=False)\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)\n",
    "x=0\n",
    "for i in range(len(gd)):\n",
    "\n",
    "    if Y_test.iloc[i] == gd[i]:\n",
    "        x=x+1\n",
    "jg=x/len(gd)\n",
    "jg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8822861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       327\n",
      "           1       0.73      0.70      0.71       322\n",
      "\n",
      "    accuracy                           0.72       649\n",
      "   macro avg       0.72      0.72      0.72       649\n",
      "weighted avg       0.72      0.72      0.72       649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(Y_test,gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97d0901b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[243,  84],\n",
       "       [ 97, 225]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm=confusion_matrix(Y_test,gd,labels=[0,1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7cd0b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'true')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "ax = sn.heatmap(cm,annot=True,fmt='.20g',cmap=\"Blues\")\n",
    "ax.set_title('confusion matrix 1') #title\n",
    "ax.set_xlabel('predict') #x axis\n",
    "ax.set_ylabel('true') #y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab7f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
